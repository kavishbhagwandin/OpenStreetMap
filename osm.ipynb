{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcbfd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmium\n",
    "from geopy.distance import geodesic\n",
    "from shapely import wkb as wkblib\n",
    "import json\n",
    "from scipy import spatial\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee90914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the amount of sports related places BEFORE: 50171\n",
      "the amount of sports related places AFTER: 50171\n"
     ]
    }
   ],
   "source": [
    "class TagHandler(osmium.SimpleHandler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sport_places = []\n",
    "        self.context_list = []\n",
    "        self.geometry_gen = osmium.geom.WKBFactory()\n",
    "\n",
    "    def node(self, n):\n",
    "       \n",
    "        tags_dict = dict(n.tags)\n",
    "        tag_keys = list(tags_dict.keys())\n",
    "        loc = (n.location.lat, n.location.lon)\n",
    "\n",
    "        if(\n",
    "            tags_dict.get(\"building\") == \"sports_centre\"\n",
    "            or tags_dict.get(\"leisure\") == \"sports_centre\"\n",
    "            or \"sport\" in tags_dict\n",
    "        ):\n",
    "            self.sport_places.append({\n",
    "                \"location\": loc,\n",
    "                \"tags\": tag_keys\n",
    "            })\n",
    "\n",
    "        \n",
    "        if tags_dict.get(\"leisure\") == \"park\":\n",
    "            self.context_list.append((\"park\", loc))\n",
    "        elif tags_dict.get(\"amenity\") == \"school\":\n",
    "            self.context_list.append((\"school\", loc))\n",
    "        elif tags_dict.get(\"building\") == \"apartment\":\n",
    "            self.context_list.append((\"apartment\", loc))\n",
    "        elif tags_dict.get(\"building\") == \"house\":\n",
    "            self.context_list.append((\"house\", loc))\n",
    "    \n",
    "    def way(self, w):\n",
    "       \n",
    "        tags_dict = dict(w.tags)\n",
    "        tag_keys = list(tags_dict.keys())\n",
    "\n",
    "        if(\n",
    "            tags_dict.get(\"building\") == \"sports_centre\"\n",
    "            or tags_dict.get(\"building\") == \"sports_hall\"\n",
    "            or tags_dict.get(\"leisure\") == \"sports_centre\"\n",
    "            or tags_dict.get(\"leisure\") == \"sports_hall\"\n",
    "            or \"sport\" in tags_dict\n",
    "        ):\n",
    "            #this is done because these are polygons and they do not have\n",
    "            #just one coordinate, so from the polygon, we calculate the center of it\n",
    "            #and use that as its location\n",
    "            loc = None\n",
    "            try:\n",
    "                wkb = self.geometry_gen.create_multipolygon(w)\n",
    "                shape = wkblib.loads(wkb, hex=True)\n",
    "                centroid = shape.centroid\n",
    "                loc = (centroid.y, centroid.x)\n",
    "                \n",
    "            #if calculating the center coordinate fails, it means the polygon was incomplete\n",
    "            #so we instead use a valid node that makes up the polygon as its coordinate/location\n",
    "            except Exception:\n",
    "                for node in w.nodes:\n",
    "                    if node.location.valid():\n",
    "                        loc = (node.location.lat, node.location.lon)\n",
    "                        break\n",
    "\n",
    "            if loc:\n",
    "                self.sport_places.append({\n",
    "                    \"location\": loc,\n",
    "                    \"tags\": tag_keys\n",
    "                })\n",
    "\n",
    "        context_tags = {\n",
    "            \"leisure\": \"park\",\n",
    "            \"amenity\": \"school\",\n",
    "            \"building\": [\"apartments\", \"house\", \"residential\"]\n",
    "        }\n",
    "\n",
    "        loc = None\n",
    "        \n",
    "        try:\n",
    "            wkb = self.geometry_gen.create_multipolygon(w)\n",
    "            shape = wkblib.loads(wkb, hex=True)\n",
    "            centroid = shape.centroid\n",
    "            loc = (centroid.y, centroid.x)\n",
    "\n",
    "            \n",
    "        except Exception:\n",
    "             for node in w.nodes:\n",
    "                if node.location.valid():\n",
    "                    loc = (node.location.lat, node.location.lon)\n",
    "                    break\n",
    "        \n",
    "        if loc:\n",
    "            for key, value in context_tags.items():\n",
    "                if isinstance(value, list):\n",
    "                    if tags_dict.get(key) in value:\n",
    "                        self.context_list.append((tags_dict.get(key), loc))\n",
    "                elif tags_dict.get(key) == value:\n",
    "                    self.context_list.append((value, loc))\n",
    "        \n",
    "       \n",
    "    \n",
    "\n",
    "osm_file = \"netherlands-latest.osm.pbf\"\n",
    "tag_holder = TagHandler()\n",
    "tag_holder.apply_file(osm_file, locations= True)\n",
    "\n",
    "print(f\"the amount of sports related places BEFORE: {len(tag_holder.sport_places)}\")\n",
    "#group context with all their locations\n",
    "filtered_data = []\n",
    "grouped_context = defaultdict(list)\n",
    "for type_of_ctx, (lat, lon) in tag_holder.context_list:\n",
    "    grouped_context[type_of_ctx].append((lat, lon))\n",
    "\n",
    "#makes a kdtree for each context\n",
    "context_tree = {}\n",
    "for context, locations in grouped_context.items():\n",
    "    coordinates = [(lon, lat) for lat, lon in locations]\n",
    "    context_tree[context] = spatial.KDTree(coordinates)\n",
    "\n",
    "#loop through the sport places\n",
    "for sport_place in tag_holder.sport_places:\n",
    "    location = sport_place[\"location\"]\n",
    "    lat, lon = location\n",
    "    target = (lon, lat)\n",
    "    tags = list(sport_place[\"tags\"])\n",
    "    #loop through each context and its related tree\n",
    "    for context_type, tree in context_tree.items():\n",
    "        nearby_locations = tree.query_ball_point(target, r=0.002)\n",
    "        if nearby_locations:\n",
    "            tags.append(f\"near_{context_type}\")\n",
    "\n",
    "    filtered_data.append(tags)\n",
    "\n",
    "\n",
    "print(f\"the amount of sports related places AFTER: {len(filtered_data)}\")\n",
    "\n",
    "train_data, test_data = train_test_split(filtered_data, test_size=0.2, random_state=42)\n",
    "\n",
    "with open(\"train_w_ctx_NL.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for tag_list in train_data:\n",
    "        f.write(\"\\t\".join(tag_list) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@1: 0.774749498997996\n",
      "Recall@1: 0.774749498997996\n",
      "Precision@3: 0.30701402805613986\n",
      "Recall@3: 0.9210420841683367\n",
      "Precision@5: 0.18857715430864638\n",
      "Recall@5: 0.9428857715430862\n",
      "Precision@10: 0.096002004008031\n",
      "Recall@10: 0.9600200400801603\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import requests\n",
    "\n",
    "def evaluate_model(test_data, k):\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "\n",
    "    for tag_set in test_data:\n",
    "        non_context_tags = []\n",
    "        for t in tag_set:\n",
    "            if not t.startswith(\"near\"):\n",
    "                non_context_tags.append(t)\n",
    "                \n",
    "        # we need at least 3 non-context tags for the back-off model, because 1 is going to be left out.\n",
    "        if len(non_context_tags) < 2:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        for el in tag_set:\n",
    "            if el.startswith(\"near\"):\n",
    "                temp.append(el)\n",
    "                tag_set.remove(el)\n",
    "\n",
    "        left_out_tags = random.sample(tag_set, k=1) \n",
    "        input_tags = []\n",
    "        for t in tag_set:\n",
    "            if t not in left_out_tags:\n",
    "                input_tags.append(t)\n",
    "\n",
    "        for i in temp:\n",
    "            if len(temp) == 0:\n",
    "                break\n",
    "            else:\n",
    "                input_tags.append(i)\n",
    "\n",
    "            \n",
    "\n",
    "        tags ={ \"properties\": input_tags,\n",
    "                \"types\": []}\n",
    "        response = requests.post(\"http://localhost:8080/recommender\", json=tags)\n",
    "        recommendations = response.json()\n",
    "\n",
    "        recommended_tags = []\n",
    "        for recom in recommendations[\"recommendations\"]:\n",
    "            tag = recom[\"property\"]\n",
    "            if not tag.startswith(\"near\"):\n",
    "                recommended_tags.append(tag)\n",
    "            if len(recommended_tags) == k:\n",
    "                break\n",
    "        \n",
    "        existing_tags = []\n",
    "        for tag in recommended_tags:\n",
    "            if tag in left_out_tags:\n",
    "                existing_tags.append(tag)\n",
    "        true_pos = len(existing_tags)\n",
    "        precision = true_pos / k\n",
    "        recall = true_pos / len(left_out_tags)\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    average_precision_score = sum(precision_scores) / len(precision_scores)\n",
    "    average_recall_score = sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "    return average_precision_score, average_recall_score\n",
    "\n",
    "\n",
    "precision_model, recall_model = evaluate_model(test_data, k=1)\n",
    "print(f\"Precision@1: {precision_model}\")\n",
    "print(f\"Recall@1: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model(test_data, k=3)\n",
    "print(f\"Precision@3: {precision_model}\")\n",
    "print(f\"Recall@3: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model(test_data, k=5)\n",
    "print(f\"Precision@5: {precision_model}\")\n",
    "print(f\"Recall@5: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model(test_data, k=10)\n",
    "print(f\"Precision@10: {precision_model}\")\n",
    "print(f\"Recall@10: {recall_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b89c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy used is max\n",
      "Precision@1: 0.7687203791469195\n",
      "Recall@1: 0.7687203791469195\n",
      "Strategy used is avg\n",
      "Precision@1: 0.7723222748815166\n",
      "Recall@1: 0.7723222748815166\n",
      "\n",
      "\n",
      "Strategy used is max\n",
      "Precision@3: 0.28834123222747554\n",
      "Recall@3: 0.8650236966824645\n",
      "Strategy used is avg\n",
      "Precision@3: 0.2928909952606498\n",
      "Recall@3: 0.8786729857819905\n",
      "\n",
      "\n",
      "Strategy used is max\n",
      "Precision@5: 0.17827488151660223\n",
      "Recall@5: 0.8913744075829384\n",
      "Strategy used is avg\n",
      "Precision@5: 0.17804739336494343\n",
      "Recall@5: 0.8902369668246446\n",
      "\n",
      "\n",
      "Strategy used is max\n",
      "Precision@10: 0.0919052132701501\n",
      "Recall@10: 0.9190521327014218\n",
      "Strategy used is avg\n",
      "Precision@10: 0.09186729857820695\n",
      "Recall@10: 0.9186729857819905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_model_backoff(test_data, strat, k):\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "\n",
    "    for tag_set in test_data:\n",
    "        non_context_tags = []\n",
    "        for t in tag_set:\n",
    "            if not t.startswith(\"near\"):\n",
    "                non_context_tags.append(t)\n",
    "                \n",
    "        # we need at least 3 non-context tags for the back-off model, because 1 is going to be left out.\n",
    "        if len(non_context_tags) < 3:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        for el in tag_set:\n",
    "            if el.startswith(\"near\"):\n",
    "                temp.append(el)\n",
    "                tag_set.remove(el)\n",
    "\n",
    "        left_out_tags = random.sample(tag_set, k=1) \n",
    "\n",
    "        input_tags = []\n",
    "        for t in tag_set:\n",
    "            if t not in left_out_tags:\n",
    "                input_tags.append(t)\n",
    "\n",
    "        P1 = input_tags[::2]\n",
    "        P2 = input_tags[1::2]\n",
    "\n",
    "        for i in temp:\n",
    "            if len(temp) == 0:\n",
    "                break\n",
    "            else:\n",
    "                P1.append(i)\n",
    "                P2.append(i)\n",
    "\n",
    "            \n",
    "        \n",
    "        def get_clean_recommendations(input, other_input):\n",
    "            tags ={ \"properties\": input,\n",
    "                \"types\": []}\n",
    "            response = requests.post(\"http://localhost:8080/recommender\", json=tags)\n",
    "            recommendations = response.json()\n",
    "            cleaned = {}\n",
    "            for rec in recommendations[\"recommendations\"]:\n",
    "                tag = rec[\"property\"]\n",
    "                score = rec[\"probability\"]\n",
    "                if not tag.startswith(\"near\") and tag not in other_input:\n",
    "                    cleaned[tag] = score\n",
    "                if len(cleaned) == k:\n",
    "                    break\n",
    "            return cleaned\n",
    "        \n",
    "        recommended1 = get_clean_recommendations(P1, P2)\n",
    "        recommended2 = get_clean_recommendations(P2, P1)\n",
    "\n",
    "        merged_recommendations = defaultdict(list)\n",
    "        for tag, prob in recommended1.items():\n",
    "            merged_recommendations[tag].append(prob)\n",
    "        for tag, prob in recommended2.items():\n",
    "            merged_recommendations[tag].append(prob)\n",
    "        \n",
    "        \n",
    "        final_recommendations = []\n",
    "        for tag, prob in merged_recommendations.items():\n",
    "            if strat == \"max\":\n",
    "                final_recommendations.append((tag, max(prob)))\n",
    "            if strat == \"avg\":\n",
    "                final_recommendations.append((tag, sum(prob) / len(prob)))\n",
    "            \n",
    "        final_recommendations.sort(key=lambda x: x[1], reverse= True)\n",
    "        final_k_recommendations = []\n",
    "        for t, s in final_recommendations:\n",
    "            final_k_recommendations.append(t)\n",
    "            if len(final_k_recommendations) == k:\n",
    "                break\n",
    "                \n",
    "        existing_tags = []\n",
    "        for tag in final_k_recommendations:\n",
    "            if tag in left_out_tags:\n",
    "                existing_tags.append(tag)\n",
    "        true_pos = len(existing_tags)\n",
    "        precision = true_pos / k\n",
    "        recall = true_pos / len(left_out_tags)\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    average_precision_score = sum(precision_scores) / len(precision_scores)\n",
    "    average_recall_score = sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "    return average_precision_score, average_recall_score\n",
    "\n",
    "strat_m = \"max\"\n",
    "strat_a = \"avg\"\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_m, k=1)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@1: {precision_model}\")\n",
    "print(f\"Recall@1: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_a, k=1)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@1: {precision_model}\")\n",
    "print(f\"Recall@1: {recall_model}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_m, k=3)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@3: {precision_model}\")\n",
    "print(f\"Recall@3: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_a, k=3)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@3: {precision_model}\")\n",
    "print(f\"Recall@3: {recall_model}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_m, k=5)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@5: {precision_model}\")\n",
    "print(f\"Recall@5: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_a, k=5)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@5: {precision_model}\")\n",
    "print(f\"Recall@5: {recall_model}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_m, k=10)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@10: {precision_model}\")\n",
    "print(f\"Recall@10: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff(test_data, strat_a, k=10)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@10: {precision_model}\")\n",
    "print(f\"Recall@10: {recall_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce50380",
   "metadata": {},
   "source": [
    "#below are the models without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "037a0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_no_ctx = []\n",
    "for sport_place in tag_holder.sport_places:\n",
    "    tags_no_ctx = list(sport_place[\"tags\"])\n",
    "    filtered_data_no_ctx.append(tags_no_ctx)\n",
    "\n",
    "with open(\"filtered_data_no_ctx.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for tag_list in filtered_data_no_ctx:\n",
    "        f.write(\"\\t\".join(tag_list) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f010984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_ctx_data, test_no_ctx_data = train_test_split(filtered_data_no_ctx, test_size=0.2, random_state=42)\n",
    "\n",
    "with open(\"train_no_ctx_NL.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for tag_list in train_no_ctx_data:\n",
    "        f.write(\"\\t\".join(tag_list) + \"\\n\")\n",
    "\n",
    "with open(\"test_no_ctx_NL.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for tag_list in test_no_ctx_data:\n",
    "        f.write(\"\\t\".join(tag_list) + \"\\n\")\n",
    "\n",
    "with open(\"test_data_no_ctx_NL.pkl\", \"wb\") as f:\n",
    "    pickle.dump(filtered_data_no_ctx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed134d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@1: 0.8596192384769539\n",
      "Recall@1: 0.8596192384769539\n",
      "\n",
      "\n",
      "Precision@3: 0.30838343353376235\n",
      "Recall@3: 0.9251503006012024\n",
      "\n",
      "\n",
      "Precision@5: 0.18873747494992898\n",
      "Recall@5: 0.943687374749499\n",
      "\n",
      "\n",
      "Precision@10: 0.09604208416835164\n",
      "Recall@10: 0.9604208416833667\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import requests\n",
    "\n",
    "def evaluate_model_no_ctx(test_no_ctx_data, k):\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "\n",
    "    for tag_set in test_no_ctx_data:\n",
    "        if len(tag_set) < 2:\n",
    "            continue\n",
    "\n",
    "        left_out_tags = random.sample(tag_set, k=1) \n",
    "        input_tags = []\n",
    "        for t in tag_set:\n",
    "            if t not in left_out_tags:\n",
    "                input_tags.append(t)\n",
    "\n",
    "\n",
    "        tags ={ \"properties\": input_tags,\n",
    "                \"types\": []}\n",
    "        response = requests.post(\"http://localhost:8080/recommender\", json=tags)\n",
    "        recommendations = response.json()\n",
    "\n",
    "        recommended_tags = []\n",
    "        for recom in recommendations[\"recommendations\"]:\n",
    "            tag = recom[\"property\"]\n",
    "            if not tag.startswith(\"near\"):\n",
    "                recommended_tags.append(tag)\n",
    "            if len(recommended_tags) == k:\n",
    "                break\n",
    "        \n",
    "        existing_tags = []\n",
    "        for tag in recommended_tags:\n",
    "            if tag in left_out_tags:\n",
    "                existing_tags.append(tag)\n",
    "        true_pos = len(existing_tags)\n",
    "        precision = true_pos / k\n",
    "        recall = true_pos / len(left_out_tags)\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    average_precision_score = sum(precision_scores) / len(precision_scores)\n",
    "    average_recall_score = sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "    return average_precision_score, average_recall_score\n",
    "\n",
    "\n",
    "precision_model, recall_model = evaluate_model_no_ctx(test_no_ctx_data, k=1)\n",
    "print(f\"Precision@1: {precision_model}\")\n",
    "print(f\"Recall@1: {recall_model}\")\n",
    "print(\"\\n\")\n",
    "precision_model, recall_model = evaluate_model_no_ctx(test_no_ctx_data, k=3)\n",
    "print(f\"Precision@3: {precision_model}\")\n",
    "print(f\"Recall@3: {recall_model}\")\n",
    "print(\"\\n\")\n",
    "precision_model, recall_model = evaluate_model_no_ctx(test_no_ctx_data, k=5)\n",
    "print(f\"Precision@5: {precision_model}\")\n",
    "print(f\"Recall@5: {recall_model}\")\n",
    "print(\"\\n\")\n",
    "precision_model, recall_model = evaluate_model_no_ctx(test_no_ctx_data, k=10)\n",
    "print(f\"Precision@10: {precision_model}\")\n",
    "print(f\"Recall@10: {recall_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854d477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy used is max\n",
      "Precision@1: 0.7717535545023697\n",
      "Recall@1: 0.7717535545023697\n",
      "Strategy used is avg\n",
      "Precision@1: 0.7823696682464455\n",
      "Recall@1: 0.7823696682464455\n",
      "Strategy used is max\n",
      "Precision@3: 0.28834123222747554\n",
      "Recall@3: 0.8650236966824645\n",
      "Strategy used is avg\n",
      "Precision@3: 0.28960505529224617\n",
      "Recall@3: 0.8688151658767772\n",
      "Strategy used is max\n",
      "Precision@5: 0.17850236966826105\n",
      "Recall@5: 0.8925118483412322\n",
      "Strategy used is avg\n",
      "Precision@5: 0.17630331753555914\n",
      "Recall@5: 0.8815165876777251\n",
      "Strategy used is max\n",
      "Precision@10: 0.09186729857820695\n",
      "Recall@10: 0.9186729857819905\n",
      "Strategy used is avg\n",
      "Precision@10: 0.09211374407583735\n",
      "Recall@10: 0.9211374407582938\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_backoff_no_ctx(test_no_ctx_data, strat, k):\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "\n",
    "    for tag_set in test_no_ctx_data:\n",
    "        if len(tag_set) < 3:\n",
    "            continue\n",
    "\n",
    "\n",
    "        left_out_tags = random.sample(tag_set, k=1) \n",
    "        input_tags = []\n",
    "        for t in tag_set:\n",
    "            if t not in left_out_tags:\n",
    "                input_tags.append(t)\n",
    "\n",
    "        P1 = input_tags[::2]\n",
    "        P2 = input_tags[1::2]\n",
    "\n",
    "        \n",
    "        def get_clean_recommendations(input, other_input):\n",
    "            tags ={ \"properties\": input,\n",
    "                \"types\": []}\n",
    "            response = requests.post(\"http://localhost:8080/recommender\", json=tags)\n",
    "            recommendations = response.json()\n",
    "            cleaned = {}\n",
    "            for rec in recommendations[\"recommendations\"]:\n",
    "                tag = rec[\"property\"]\n",
    "                score = rec[\"probability\"]\n",
    "                if tag not in other_input:\n",
    "                    cleaned[tag] = score\n",
    "                if len(cleaned) == k:\n",
    "                    break\n",
    "            return cleaned\n",
    "        \n",
    "        recommended1 = get_clean_recommendations(P1, P2)\n",
    "        recommended2 = get_clean_recommendations(P2, P1)\n",
    "\n",
    "        merged_recommendations = defaultdict(list)\n",
    "        for tag, prob in recommended1.items():\n",
    "            merged_recommendations[tag].append(prob)\n",
    "        for tag, prob in recommended2.items():\n",
    "            merged_recommendations[tag].append(prob)\n",
    "        \n",
    "        \n",
    "        final_recommendations = []\n",
    "        for tag, prob in merged_recommendations.items():\n",
    "            if strat == \"max\":\n",
    "                final_recommendations.append((tag, max(prob)))\n",
    "            if strat == \"avg\":\n",
    "                final_recommendations.append((tag, sum(prob) / len(prob)))\n",
    "            \n",
    "        final_recommendations.sort(key=lambda x: x[1], reverse= True)\n",
    "        final_k_recommendations = []\n",
    "        for t, s in final_recommendations:\n",
    "            final_k_recommendations.append(t)\n",
    "            if len(final_k_recommendations) == k:\n",
    "                break\n",
    "                \n",
    "        existing_tags = []\n",
    "        for tag in final_k_recommendations:\n",
    "            if tag in left_out_tags:\n",
    "                existing_tags.append(tag)\n",
    "        true_pos = len(existing_tags)\n",
    "        precision = true_pos / k\n",
    "        recall = true_pos / len(left_out_tags)\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    average_precision_score = sum(precision_scores) / len(precision_scores)\n",
    "    average_recall_score = sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "    return average_precision_score, average_recall_score\n",
    "\n",
    "strat_m = \"max\"\n",
    "strat_a = \"avg\"\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_m, k=1)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@1: {precision_model}\")\n",
    "print(f\"Recall@1: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_a, k=1)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@1: {precision_model}\")\n",
    "print(f\"Recall@1: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_m, k=3)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@3: {precision_model}\")\n",
    "print(f\"Recall@3: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_a, k=3)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@3: {precision_model}\")\n",
    "print(f\"Recall@3: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_m, k=5)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@5: {precision_model}\")\n",
    "print(f\"Recall@5: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_a, k=5)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@5: {precision_model}\")\n",
    "print(f\"Recall@5: {recall_model}\")\n",
    "\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_m, k=10)\n",
    "print(f\"Strategy used is {strat_m}\")\n",
    "print(f\"Precision@10: {precision_model}\")\n",
    "print(f\"Recall@10: {recall_model}\")\n",
    "\n",
    "precision_model, recall_model = evaluate_model_backoff_no_ctx(test_no_ctx_data, strat_a, k=10)\n",
    "print(f\"Strategy used is {strat_a}\")\n",
    "print(f\"Precision@10: {precision_model}\")\n",
    "print(f\"Recall@10: {recall_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
